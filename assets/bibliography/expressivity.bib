@article{child2019generating,
    title         = {Generating Long Sequences with Sparse Transformers},
    author        = {Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
    year          = 2019,
    url           = {http://arxiv.org/abs/1904.10509},
}

@inproceedings{papernot2016crafting,
    title         = {Crafting adversarial input sequences for recurrent neural networks},
    author        = {Papernot, Nicolas and McDaniel, Patrick and Swami, Ananthram and Harang, Richard},
    year          = 2016,
    booktitle     = {MILCOM},
    publisher     = {IEEE Press},
    url           = {https://doi.org/10.1109/MILCOM.2016.7795300},
}

@article{tay2022efficient,
    title         = {Efficient Transformers: A Survey},
    author        = {Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
    year          = 2022,
    url           = {https://arxiv.org/abs/2009.06732},
}

@article{wang2020linformer,
    title         = {Linformer: Self-Attention with Linear Complexity},
    author        = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
    year          = 2020,
    url           = {https://arxiv.org/abs/2006.04768},
}

@inproceedings{weiss2021thinking,
    title         = {Thinking Like Transformers},
    author        = {Gail Weiss and Yoav Goldberg and Eran Yahav},
    year          = 2021,
    booktitle     = {PMLR},
    url           = {https://proceedings.mlr.press/v139/weiss21a.html},
    pdf           = {http://proceedings.mlr.press/v139/weiss21a/weiss21a.pdf},
}

@article{yang2020greedy,
    title         = {Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data},
    author        = {Puyudi Yang and Jianbo Chen and Cho-Jui Hsieh and Jane-Ling Wang and Michael I. Jordan},
    year          = 2020,
    journal       = {Journal of Machine Learning Research},
    url           = {http://jmlr.org/papers/v21/19-569.html},
}
